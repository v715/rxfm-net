{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "\n",
    "Rigid Transformation Network (RXFM Net)\n",
    "====\n",
    "\n",
    "Single Subject Example\n",
    "----\n",
    "\n",
    "This notebook provides example code for [our MICCAI 2021 paper](https://arxiv.org/abs/2103.10255). It roughly recreates Figure 2, the single subject two-pose experiment. It has been slightly reformatted to provide better explainations, and to use the MNI152 subject instead of an HCP subject.\n",
    "\n",
    "We'll first import the necessary libraries and variables, including the MNI152 standard filepath from nilearn. Our code expects to be running the notebook server from the repo root directory, but you can also change `src/` to the full physical path."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys\n",
    "sys.path.append('src/')\n",
    "\n",
    "import numpy as np\n",
    "import torch\n",
    "from nilearn.datasets import MNI152_FILE_PATH\n",
    "from functools import partial\n",
    "\n",
    "print(MNI152_FILE_PATH)\n",
    "\n",
    "IMG_SIZE = [96,96,96]\n",
    "\n",
    "import utils\n",
    "import losses\n",
    "import custom_image3d as ci3d\n",
    "import rxfm_net"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "After loading in the file, we'll scale and pad it to `[96,96,96]`, as well as rescaling the histogram using a simple quantile filter. We'll then create the second pose, with a known (chosen) transformation matrix. In other situations, `loader_dict` might be the output of a `DataLoader` object, but here we only have one."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "with torch.no_grad():\n",
    "    img_vol, _, _ = utils.load_scale_and_pad(MNI152_FILE_PATH, IMG_SIZE, initial_resize=[128,128,128], rescale=[96,96,96])\n",
    "\n",
    "    print(img_vol.size())\n",
    "\n",
    "    img_vol = img_vol.float()\n",
    "    mask = (img_vol > 0).float()\n",
    "\n",
    "    rx_train = 1\n",
    "    ry_train = 1\n",
    "    rz_train = 1\n",
    "    tx_train = 5\n",
    "    ty_train = 5\n",
    "    tz_train = 5\n",
    "\n",
    "    mat = ci3d.create_transform(\n",
    "        rx=rx_train, ry=ry_train, rz=rz_train,\n",
    "        tx=2.0*tx_train/IMG_SIZE[0], ty=2.0*ty_train/IMG_SIZE[1], tz=2.0*tz_train/IMG_SIZE[2]\n",
    "    )\n",
    "    \n",
    "    mat = mat[np.newaxis,:,:]\n",
    "    mat = mat[:,0:3,:]\n",
    "    mat = torch.tensor(mat).float()\n",
    "\n",
    "    print(mat)\n",
    "    grids = torch.nn.functional.affine_grid(mat, [1,1] + IMG_SIZE)\n",
    "    second_img_vol = torch.nn.functional.grid_sample(\n",
    "      img_vol, grids, mode=\"bilinear\"\n",
    "    ).detach()\n",
    "    second_mask = (second_img_vol > 0).float()\n",
    "\n",
    "loader_dict = {\n",
    "    \"scan_1\" : img_vol,\n",
    "    \"mask_1\" : mask,\n",
    "    \"scan_2\" : second_img_vol,\n",
    "    \"mask_2\" : second_mask,\n",
    "    \"xfm_1to2\" : mat\n",
    "}\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Visualization\n",
    "----\n",
    "Let's visualize these images:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "\n",
    "%matplotlib inline\n",
    "\n",
    "from nilearn import plotting\n",
    "import seaborn_image as isns\n",
    "\n",
    "def plotting_function(vol,x,y,z,ax):\n",
    "    isns.imgplot( np.transpose(vol[x,:,:]), cbar=False, gray=True, ax=ax[0])\n",
    "    isns.imgplot( np.transpose(vol[:,y,:]), cbar=False, gray=True, ax=ax[1])\n",
    "    isns.imgplot( vol[:,:,z], cbar=False, gray=True, ax=ax[2])\n",
    "    plt.show()\n",
    "\n",
    "fig_end, ax_start = plt.subplots(1,3)\n",
    "plotting_function(img_vol.numpy()[0,0,...],48,48,48,ax_start)\n",
    "fig_end, ax_end = plt.subplots(1,3)\n",
    "plotting_function(second_img_vol.numpy()[0,0,...],48,48,48,ax_end)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training and torch cargo-culting\n",
    "----\n",
    "Defining some paramters for the network:"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 1\n",
    "IMG_SIZE = [96,96,96,1]\n",
    "loss_func_name = \"xfm_6D\"\n",
    "\n",
    "n_conv_chan = 1\n",
    "n_chan = 64\n",
    "overfit = True "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "if torch.cuda.is_available():\n",
    "    device = 'cuda:0'\n",
    "else:\n",
    "    device = 'cpu'\n",
    "\n",
    "print(f\"using {device} as device\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "net_obj = rxfm_net.RXFM_Net_Wrapper(IMG_SIZE[0:3], n_chan, masks_as_input=False)\n",
    "\n",
    "if loss_func_name == \"xfm_MSE\":\n",
    "    loss_func = partial( losses.xfm_loss_MSE, weight_R=1.0, weight_T=5.0)\n",
    "elif loss_func_name == \"xfm_6D\":\n",
    "    loss_func = partial( losses.xfm_loss_6D, weight_R=1.0, weight_T=5.0)\n",
    "else:\n",
    "    print(\"Loss function not recognized\")\n",
    "    exit(1)\n",
    "\n",
    "net_obj = net_obj.to(device)\n",
    "LR = 0.000025\n",
    "optimizer = torch.optim.Adam(net_obj.parameters(), lr=LR)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Training Function and Loop\n",
    "----\n",
    "\n",
    "This is the main training function, and then the loop that runs it. We're only running for 100 epochs, but you can run it for much longer. For most seeds this seems to work, though there likely are some adversarial initializations."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def normalized_cross_correlation(x, y, return_map, reduction='mean', eps=1e-8):\n",
    "    \"\"\" N-dimensional normalized cross correlation (NCC)\n",
    "    Args:\n",
    "        x (~torch.Tensor): Input tensor.\n",
    "        y (~torch.Tensor): Input tensor.\n",
    "        return_map (bool): If True, also return the correlation map.\n",
    "        reduction (str, optional): Specifies the reduction to apply to the output:\n",
    "            ``'mean'`` | ``'sum'``. Defaults to ``'sum'``.\n",
    "        eps (float, optional): Epsilon value for numerical stability. Defaults to 1e-8.\n",
    "    Returns:\n",
    "        ~torch.Tensor: Output scalar\n",
    "        ~torch.Tensor: Output tensor\n",
    "    \"\"\"\n",
    "\n",
    "    shape = x.shape\n",
    "    b = shape[0]\n",
    "\n",
    "    # reshape\n",
    "    x = x.view(b, -1)\n",
    "    y = y.view(b, -1)\n",
    "\n",
    "    # mean\n",
    "    x_mean = torch.mean(x, dim=1, keepdim=True)\n",
    "    y_mean = torch.mean(y, dim=1, keepdim=True)\n",
    "\n",
    "    # deviation\n",
    "    x = x - x_mean\n",
    "    y = y - y_mean\n",
    "\n",
    "    dev_xy = torch.mul(x,y)\n",
    "    dev_xx = torch.mul(x,x)\n",
    "    dev_yy = torch.mul(y,y)\n",
    "\n",
    "    dev_xx_sum = torch.sum(dev_xx, dim=1, keepdim=True)\n",
    "    dev_yy_sum = torch.sum(dev_yy, dim=1, keepdim=True)\n",
    "\n",
    "    ncc = torch.div(dev_xy + eps / dev_xy.shape[1],\n",
    "                    torch.sqrt( torch.mul(dev_xx_sum, dev_yy_sum)) + eps)\n",
    "    ncc_map = ncc.view(b, *shape[1:])\n",
    "\n",
    "    # reduce\n",
    "    if reduction == 'mean':\n",
    "        ncc = torch.mean(torch.sum(ncc, dim=1))\n",
    "    elif reduction == 'sum':\n",
    "        ncc = torch.sum(ncc)\n",
    "    else:\n",
    "        raise KeyError('unsupported reduction type: %s' % reduction)\n",
    "\n",
    "    if not return_map:\n",
    "        return ncc\n",
    "\n",
    "    return ncc, ncc_map"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_func( net_obj, optimizer, loss_func, loader_dict ):\n",
    "    input_1 = loader_dict[\"scan_1\"].to(device)\n",
    "    input_2 = loader_dict[\"scan_2\"].to(device)\n",
    "\n",
    "    optimizer.zero_grad()\n",
    "\n",
    "    #remember xfm is flipped during affine_grid\n",
    "    # from\n",
    "    # https://discuss.pytorch.org/t/unexpected-behaviour-for-affine-grid-and-grid-sample-with-3d-inputs/75010/5\n",
    "    #net_obj MUST take both scans as input, and output a transform between them.\n",
    "    # for rxfm net, the forward operator with only one scan should be implemented\n",
    "    # separately!!! \n",
    "    xfm_1to2, output_1, output_2 = net_obj.forward((input_1,input_2))\n",
    "\n",
    "    # XFM LOSS\n",
    "    real_xfm_1to2 = loader_dict[\"xfm_1to2\"].to(device)\n",
    "    loss_val = loss_func( real_xfm_1to2, xfm_1to2 ) + normalized_cross_correlation(output_1, output_2, return_map=False)\n",
    "\n",
    "    loss_val.backward(retain_graph=True)\n",
    "    optimizer.step()\n",
    "\n",
    "    train_loss = loss_val.item()*batch_size\n",
    "\n",
    "    print(real_xfm_1to2)\n",
    "    print(xfm_1to2)\n",
    "\n",
    "    del real_xfm_1to2\n",
    "    del loss_val\n",
    "    del xfm_1to2 #, dist_xfm_1to2\n",
    "    del input_1, input_2\n",
    "    torch.cuda.empty_cache()\n",
    "    \n",
    "    return train_loss, output_1, output_2"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "n_epochs = 100\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "\n",
    "    ##\n",
    "    ## train loop\n",
    "    ##\n",
    "    \n",
    "    print(epoch, flush=True)\n",
    "\n",
    "    train_loss = 0\n",
    "    #THIS WOULD USUALLY BE A LOADER, but we only have one datapoint anyway...\n",
    "    #for d_idx,loader_dict in enumerate(train_loader):\n",
    "    #    print(d_idx, flush=True)\n",
    "    train_loss = train_func( net_obj, optimizer, loss_func, loader_dict )\n",
    "\n",
    "    #train_loss = train_loss / len(dataset)\n",
    "\n",
    "    print('Epoch: {} \\tTraining Loss: {:.6f}'.format(epoch, train_loss), flush=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Interactive Demo\n",
    "----\n",
    "\n",
    "And now, the fun part: an interactive demo of the network rigidly registering things. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipywidgets as widgets\n",
    "from ipywidgets import interact, interact_manual\n",
    "\n",
    "tx_widget = widgets.FloatSlider(\n",
    "    value=0.0, min=-10.0, max=10.0, step=0.1, description='Translation in X: (in vox)', continuous_update=False\n",
    ")\n",
    "\n",
    "ty_widget = widgets.FloatSlider(\n",
    "    value=0.0, min=-10.0, max=10.0, step=0.1, description='Translation in Y (in vox):', continuous_update=False\n",
    ")\n",
    "\n",
    "tz_widget = widgets.FloatSlider(\n",
    "    value=0.0, min=-10.0, max=10.0, step=0.1, description='Translation in Z (in vox):', continuous_update=False\n",
    ")\n",
    "\n",
    "rx_widget = widgets.FloatSlider(\n",
    "    value=0.0, min=-1, max=1, step=0.1, description='Rotation X-axis (in pi rad):', continuous_update=False\n",
    ")\n",
    "\n",
    "ry_widget = widgets.FloatSlider(\n",
    "    value=0.0, min=-1, max=1, step=0.1, description='Rotation Y-axis (in pi rad):', continuous_update=False\n",
    ")\n",
    "\n",
    "rz_widget = widgets.FloatSlider(\n",
    "    value=0.0, min=-1, max=1, step=0.1, description='Rotation Z-axis (in pi rad):', continuous_update=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "vol = img_vol[0,0,...].cpu()\n",
    "#this jupyter magick makes the notebook update the current plot instead of building a new plot each time...I think\n",
    "#%matplotlib widget\n",
    "%matplotlib inline\n",
    "from pytorch3d import transforms as pt3d_xfms\n",
    "\n",
    "net_obj.eval()\n",
    "\n",
    "def interactive_funky_times(vol,rx,ry,rz,tx,ty,tz):\n",
    "    fig1, ax1 = plt.subplots(1,3)\n",
    "    plotting_function(vol.detach().cpu().numpy(),48,48,48,ax1)\n",
    "\n",
    "    mat = ci3d.create_transform(rx=rx*np.pi, ry=ry*np.pi, rz=rz*np.pi, tx=2.0*tx/96, ty=2.0*ty/96, tz=2.0*tz/96)\n",
    "    print(\"Starting Volume:\")\n",
    "    print(\"Selected Matrix:\\n\", mat)\n",
    "    \n",
    "    mat = mat[0:3,:]\n",
    "    mat = torch.tensor(mat[np.newaxis,:,:],dtype=torch.float)\n",
    "    vol = torch.tensor(vol[np.newaxis,np.newaxis,...],dtype=torch.float)\n",
    "    grids = torch.nn.functional.affine_grid(mat, [1,1] + IMG_SIZE[0:3])\n",
    "    moved_vol = torch.nn.functional.grid_sample(\n",
    "      vol, grids, mode=\"bilinear\"\n",
    "    )\n",
    "\n",
    "    print(\"Moved Volume:\")\n",
    "    fig2, ax2 = plt.subplots(1,3)\n",
    "    plotting_function(moved_vol[0,0,...],48,48,48,ax2)\n",
    "    \n",
    "    xfm_1to2 = net_obj.forward((vol.to(device),moved_vol.to(device)))\n",
    "    xfm_1to2 = xfm_1to2.cpu()\n",
    "    #loss_val = loss_func( mat, xfm_1to2 )\n",
    "    #loss_val = loss_val.mean().item()\n",
    "\n",
    "    xfm_1to2 = xfm_1to2.cpu()\n",
    "    print(\"Approx Matrix:\\n\",xfm_1to2.detach().numpy())\n",
    "    #print(\"Loss val:\",loss_val)\n",
    "    print(\"Approx Moved Vol\")\n",
    "    grids = torch.nn.functional.affine_grid(xfm_1to2, [1,1] + IMG_SIZE[0:3])\n",
    "    moved_vol = torch.nn.functional.grid_sample(\n",
    "      vol, grids, mode=\"bilinear\"\n",
    "    )\n",
    "\n",
    "    fig3, ax3 = plt.subplots(1,3)\n",
    "    plotting_function(moved_vol.detach().numpy()[0,0,...],48,48,48,ax3)\n",
    "\n",
    "    rot_real = mat[:,0:3,0:3].detach().cpu().numpy()\n",
    "    trans_real = mat[:,0:3,3:].detach().cpu().numpy()\n",
    "    \n",
    "    rot_approx = xfm_1to2[:,0:3,0:3].detach().cpu().numpy()\n",
    "    trans_approx = xfm_1to2[:,0:3,3:].detach().cpu().numpy()\n",
    "\n",
    "    print(trans_real)\n",
    "    print(trans_approx)\n",
    "    \n",
    "    angles_real = pt3d_xfms.matrix_to_euler_angles(torch.tensor(rot_real[0,:,:]), convention=\"XYZ\")\n",
    "    angles_approx = pt3d_xfms.matrix_to_euler_angles(torch.tensor(rot_approx[0,:,:]), convention=\"XYZ\")\n",
    "\n",
    "    print(angles_real)\n",
    "    print(angles_approx)\n",
    "    \n",
    "    print(\"angular abs. error (mean degrees)\", np.rad2deg(np.mean(np.abs(np.array(angles_real) - np.array(angles_approx)))))\n",
    "    print(\"trans error\", np.linalg.norm(trans_real - trans_approx))\n",
    "\n",
    "#interact_manual(\n",
    "interact(\n",
    "    interactive_funky_times,\n",
    "    vol=widgets.fixed(vol),\n",
    "    rx=rx_widget, ry=ry_widget, rz=rz_widget,\n",
    "    tx=tx_widget, ty=ty_widget, tz=tz_widget\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
